library(tidymodels)
library(future)
library(rules)
library(Cubist)
library(rio)
df <- read.csv(pcv.csv)
df <- read.csv("pcv.csv")
View(df)
plan(multisession, workers = 4)
# Split
set.seed(123)
split <- initial_split(df, prop = 0.8)
train_data <- training(split)
test_data  <- testing(split)
cv_folds <- vfold_cv(train_data, v = 10)
View(df)
df <-
read.csv("pcv.csv") |>
select(-c(img, id, x, y))
plan(multisession, workers = 4)
# Split
set.seed(123)
split <- initial_split(df, prop = 0.8)
train_data <- training(split)
test_data  <- testing(split)
cv_folds <- vfold_cv(train_data, v = 10)
# Receita
recipe_base <- recipe(specie ~ ., data = train_data) |> step_normalize(all_predictors())
# ---------------------
# ğŸŒ² Random Forest
# ---------------------
rf_spec <- rand_forest(mtry = tune(), trees = 300, mode = "classification") |> set_engine("ranger")
# ---------------------
# ğŸŒ² Random Forest
# ---------------------
rf_spec <- rand_forest(mtry = tune(), trees = 300, mode = "classificatdion") |> set_engine("ranger")
# ---------------------
# ğŸŒ² Random Forest
# ---------------------
rf_spec <- rand_forest(mtry = tune(), trees = 300, mode = "classification") |> set_engine("ranger")
rf_grid <- grid_regular(mtry(range = c(3, 9)), levels = 4)
rf_wf <- workflow() |> add_model(rf_spec) |> add_recipe(recipe_base)
rf_res <- tune_grid(rf_wf, resamples = cv_folds, grid = rf_grid, metrics = metric_set(rmse, rsq, mae))
?rand_forest
View(df)
# Split
set.seed(123)
split <- initial_split(df, prop = 0.8, strata = specie)  # Para estratificar por classe
split <- initial_split(df, prop = 0.8)  # Para estratificar por classe
train_data <- training(split)
test_data  <- testing(split)
cv_folds <- vfold_cv(train_data, v = 10)
# Receita
recipe_base <-
recipe(specie ~ ., data = train_data) |>
step_normalize(all_predictors())
# ---------------------
# ğŸŒ² Random Forest
# ---------------------
rf_spec <-
rand_forest(mtry = tune(), trees = 300, mode = "classification") |>
set_engine("ranger")
# Divide os dados em 80% treino e 20% teste
# 'strata = specie' garante que a proporÃ§Ã£o das classes fique balanceada em treino e teste
split <- initial_split(df, prop = 0.8, strata = specie)
# Separa os conjuntos de treino e teste
train_data <- training(split)
test_data  <- testing(split)
# Cria as 10 folds de validaÃ§Ã£o cruzada estratificada
# Isso ajuda a manter a proporÃ§Ã£o das classes em cada fold
cv_folds <- vfold_cv(train_data, v = 10, strata = specie)
# Divide os dados em 80% treino e 20% teste
# 'strata = specie' garante que a proporÃ§Ã£o das classes fique balanceada em treino e teste
split <- initial_split(df, prop = 0.8)
# Separa os conjuntos de treino e teste
train_data <- training(split)
test_data  <- testing(split)
# Cria as 10 folds de validaÃ§Ã£o cruzada estratificada
# Isso ajuda a manter a proporÃ§Ã£o das classes em cada fold
cv_folds <- vfold_cv(train_data, v = 10)
# ---------------------
# ğŸ“Œ Receita de prÃ©-processamento (Recipe)
# ---------------------
# Define que a variÃ¡vel resposta Ã© 'specie'
# Normaliza todas as variÃ¡veis preditoras numÃ©ricas (passo opcional dependendo do modelo)
recipe_base <- recipe(specie ~ ., data = train_data) |>
step_normalize(all_predictors())
# ---------------------
# ğŸ“Œ Receita de prÃ©-processamento (Recipe)
# ---------------------
# Define que a variÃ¡vel resposta Ã© 'specie'
# Normaliza todas as variÃ¡veis preditoras numÃ©ricas (passo opcional dependendo do modelo)
recipe_base <-
recipe(specie ~ ., data = train_data) |>
step_normalize(all_predictors())
# ---------------------
# ğŸŒ² EspecificaÃ§Ã£o do modelo Random Forest para ClassificaÃ§Ã£o
# ---------------------
# Define o modelo de Random Forest
# Aqui usamos o motor 'ranger' e deixamos o nÃºmero de variÃ¡veis (mtry) para tunagem
rf_spec <- rand_forest(
mtry = tune(),    # ParÃ¢metro que serÃ¡ otimizado
trees = 300,      # NÃºmero de Ã¡rvores
mode = "classification"  # Agora estamos em modo de classificaÃ§Ã£o
) |> set_engine("ranger")  # Usando o pacote ranger como motor
# ---------------------
# ğŸŒ² EspecificaÃ§Ã£o do modelo Random Forest para ClassificaÃ§Ã£o
# ---------------------
# Define o modelo de Random Forest
# Aqui usamos o motor 'ranger' e deixamos o nÃºmero de variÃ¡veis (mtry) para tunagem
rf_spec <- rand_forest(
mtry = tune(),    # ParÃ¢metro que serÃ¡ otimizado
trees = 300,      # NÃºmero de Ã¡rvores
mode = "classification"  # ClassificaÃ§Ã£o
) |>
set_engine("ranger")  # Usando o pacote ranger como motor
# ---------------------
# ğŸ“Œ Grade de hiperparÃ¢metros
# ---------------------
# Cria uma grade regular de valores para mtry, de 3 a 9, com 4 nÃ­veis
rf_grid <- grid_regular(mtry(range = c(3, 9)), levels = 4)
rf_grid
# ---------------------
# ğŸ“Œ Grade de hiperparÃ¢metros
# ---------------------
# Cria uma grade regular de valores para mtry, de 3 a 9, com 4 nÃ­veis
rf_grid <- grid_regular(mtry(range = c(3, 9)), levels = 6)
rf_grid
# ---------------------
# ğŸ“Œ Grade de hiperparÃ¢metros
# ---------------------
# Cria uma grade regular de valores para mtry, de 3 a 9, com 4 nÃ­veis
rf_grid <- grid_regular(mtry(range = c(3, 9)))
rf_grid
# ---------------------
# ğŸ“Œ Grade de hiperparÃ¢metros
# ---------------------
# Cria uma grade regular de valores para mtry, de 3 a 9, com 4 nÃ­veis
rf_grid <- grid_regular(mtry(range = c(3, 9)), levels = 7)
rf_grid
# ---------------------
# ğŸ“Œ Workflow
# ---------------------
# Combina a receita e o modelo em um fluxo de trabalho (workflow)
rf_wf <-
workflow() |>
add_model(rf_spec) |>
add_recipe(recipe_base)
# ---------------------
# ğŸ“Œ Tunagem por validaÃ§Ã£o cruzada
# ---------------------
# Realiza a busca pela melhor combinaÃ§Ã£o de hiperparÃ¢metros da grade
# Avalia usando as mÃ©tricas de classificaÃ§Ã£o: Accuracy, ROC AUC e Kappa
rf_res <- tune_grid(
rf_wf,                   # Workflow contendo receita e modelo
resamples = cv_folds,    # As folds de validaÃ§Ã£o cruzada
grid = rf_grid,          # A grade de hiperparÃ¢metros
metrics = metric_set(    # Conjunto de mÃ©tricas de avaliaÃ§Ã£o
accuracy,              # AcurÃ¡cia
roc_auc,               # Ãrea sob a curva ROC
kap                    # Kappa de Cohen
)
)
# ---------------------
# ğŸ“Œ SeleÃ§Ã£o dos melhores hiperparÃ¢metros
# ---------------------
best_rf <- select_best(rf_res, metric = "accuracy")  # Seleciona a melhor combinaÃ§Ã£o com base na acurÃ¡cia
best_rf
# ---------------------
# ğŸ“Œ FinalizaÃ§Ã£o do Workflow com os melhores parÃ¢metros
# ---------------------
final_rf_wf <- finalize_workflow(rf_wf, best_rf)
# ---------------------
# ğŸ“Œ Ajuste final no conjunto de treino + avaliaÃ§Ã£o no conjunto de teste
# ---------------------
final_rf_fit <- last_fit(final_rf_wf, split = split, metrics = metric_set(accuracy, roc_auc, kap))
# ---------------------
# ğŸ“Œ Resultados finais
# ---------------------
# MÃ©tricas no conjunto de teste
collect_metrics(final_rf_fit)
# PrevisÃµes no conjunto de teste (se quiser visualizar ou salvar)
final_predictions <- collect_predictions(final_rf_fit)
final_predictions
View(final_predictions)
# Matriz de confusÃ£o
conf_mat(final_predictions, truth = specie, estimate = .pred_class)
?conf_mat
final_predictions$.pred_class
# Matriz de confusÃ£o
cm <- conf_mat(final_predictions, truth = specie, estimate = .pred_class)
plot(cm)
autoplot(cm)
?autoplot
class(cm)
?autoplot.conf_mat
best_rf
plot(best_rf)
View(final_rf_wf)
final_rf_wf[["post"]]
final_rf_fit
View(final_rf_fit)
final_rf_fit
?final_rf_fit
svm_spec <- svm_rbf(
mode = "classification",     # Modo classificaÃ§Ã£o
cost = tune(),               # ParÃ¢metro de penalizaÃ§Ã£o (C)
rbf_sigma = tune()           # ParÃ¢metro sigma do kernel RBF
) |> set_engine("kernlab")
svm_grid <- grid_regular(
cost(range = c(0.25, 2)),          # Faixa de custo
rbf_sigma(range = c(0.01, 0.1)),   # Faixa de sigma
levels = 3                         # 3 nÃ­veis para cada
)
svm_wf <-
workflow() |>
add_model(svm_spec) |>
add_recipe(recipe_base)
svm_res <- tune_grid(
svm_wf,
resamples = cv_folds,
grid = svm_grid,
metrics = metric_set(accuracy, roc_auc, kap)
)
svm_grid
svm_res <- tune_grid(
svm_wf,
resamples = cv_folds,
# grid = svm_grid,
metrics = metric_set(accuracy, roc_auc, kap)
)
knn_spec <- nearest_neighbor(
neighbors = tune()           # NÃºmero de vizinhos
) |> set_engine("kknn") |>
set_mode("classification")   # Modo classificaÃ§Ã£o
knn_grid <- grid_regular(
neighbors(range = c(3, 15)),
levels = 5
)
knn_wf <- workflow() |>
add_model(knn_spec) |>
add_recipe(recipe_base)
knn_res <- tune_grid(
knn_wf,
resamples = cv_folds,
grid = knn_grid,
metrics = metric_set(accuracy, roc_auc, kap)
)
knn_res <- tune_grid(
knn_wf,
resamples = cv_folds,
# grid = knn_grid,
metrics = metric_set(accuracy, roc_auc, kap)
)
rf_res
# ---------------------
# ğŸ“Œ SeleÃ§Ã£o dos melhores hiperparÃ¢metros
# ---------------------
best_rf <- select_best(rf_res, metric = "accuracy")  # Seleciona a melhor combinaÃ§Ã£o com base na acurÃ¡cia
summary(rf_res)
# ---------------------
# ğŸ“Œ SeleÃ§Ã£o dos melhores hiperparÃ¢metros
# ---------------------
best_rf <- select_best(rf_res, metric = "accuracy")  # Seleciona a melhor combinaÃ§Ã£o com base na acurÃ¡cia
# ---------------------
# ğŸ“Œ FinalizaÃ§Ã£o do Workflow com os melhores parÃ¢metros
# ---------------------
final_rf_wf <- finalize_workflow(rf_wf, best_rf)
# ---------------------
# ğŸ“Œ Ajuste final no conjunto de treino + avaliaÃ§Ã£o no conjunto de teste
# ---------------------
final_rf_fit <- last_fit(final_rf_wf, split = split, metrics = metric_set(accuracy, roc_auc, kap))
# ---------------------
# ğŸ“Œ Resultados finais
# ---------------------
# MÃ©tricas no conjunto de teste
collect_metrics(final_rf_fit)
# PrevisÃµes no conjunto de teste (se quiser visualizar ou salvar)
final_predictions <- collect_predictions(final_rf_fit)
# Matriz de confusÃ£o
conf_mat(final_predictions, truth = specie, estimate = .pred_class)
df |>
slice_sample(n = 1)
df2 <-
df |>
slice_sample(n = 1) |>
select(-c(specie))
predict(rf_res, new_data = df2)
predict(final_rf_fit, new_data = df2)
final_model <- extract_workflow(final_rf_fit)
predict(final_model, new_data = df2)
df |>
slice_sample(n = 1)
df2 <-
df |>
slice_sample(n = 1) |>
select(-c(specie))
final_model <- extract_workflow(final_rf_fit)
predict(final_model, new_data = df2)
df2 <-
df |>
slice_sample(n = 1) |>
select(-c(specie))
final_model <- extract_workflow(final_rf_fit)
df2
df2 <-
df |>
slice_sample(n = 1)
final_model <- extract_workflow(final_rf_fit)
predict(final_model, new_data = df2)
df2
predict(final_model, new_data = df2 |> select(-specie))
df2
df2 <-
df |>
slice_sample(n = 1)
final_model <- extract_workflow(final_rf_fit)
df2
predict(final_model, new_data = df2 |> select(-specie))
xgb_spec <- boost_tree(
trees = tune(),              # NÃºmero de Ã¡rvores
tree_depth = tune(),          # Profundidade da Ã¡rvore
learn_rate = tune(),          # Taxa de aprendizado
mode = "classification"       # Modo classificaÃ§Ã£o
) |> set_engine("xgboost")
xgb_grid <- grid_regular(
trees(range = c(100, 200)),
tree_depth(range = c(3, 9)),
learn_rate(range = c(0.05, 0.3)),
levels = 3
)
xgb_wf <- workflow() |>
add_model(xgb_spec) |>
add_recipe(recipe_base)
xgb_res <- tune_grid(
xgb_wf,
resamples = cv_folds,
grid = xgb_grid,
metrics = metric_set(accuracy, roc_auc, kap)
)
library(metan)
MTSI_index2 <-
data_ge2 %>%
waasb(ENV, GEN, REP,
resp = c(KW, NKE, PH, EH, TKW),
mresp = c("h, h, l, l, h"),
wresp = 65) %>% # Default is 50
mtsi(SI = 20)
plot(MTSI_index2)
View(MTSI_index2)
View(MTSI_index2[["MTSI"]])
