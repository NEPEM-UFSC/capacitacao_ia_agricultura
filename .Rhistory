library(tidymodels)
library(future)
library(rules)
library(Cubist)
library(rio)
df <- read.csv(pcv.csv)
df <- read.csv("pcv.csv")
View(df)
plan(multisession, workers = 4)
# Split
set.seed(123)
split <- initial_split(df, prop = 0.8)
train_data <- training(split)
test_data  <- testing(split)
cv_folds <- vfold_cv(train_data, v = 10)
View(df)
df <-
read.csv("pcv.csv") |>
select(-c(img, id, x, y))
plan(multisession, workers = 4)
# Split
set.seed(123)
split <- initial_split(df, prop = 0.8)
train_data <- training(split)
test_data  <- testing(split)
cv_folds <- vfold_cv(train_data, v = 10)
# Receita
recipe_base <- recipe(specie ~ ., data = train_data) |> step_normalize(all_predictors())
# ---------------------
# 🌲 Random Forest
# ---------------------
rf_spec <- rand_forest(mtry = tune(), trees = 300, mode = "classification") |> set_engine("ranger")
# ---------------------
# 🌲 Random Forest
# ---------------------
rf_spec <- rand_forest(mtry = tune(), trees = 300, mode = "classificatdion") |> set_engine("ranger")
# ---------------------
# 🌲 Random Forest
# ---------------------
rf_spec <- rand_forest(mtry = tune(), trees = 300, mode = "classification") |> set_engine("ranger")
rf_grid <- grid_regular(mtry(range = c(3, 9)), levels = 4)
rf_wf <- workflow() |> add_model(rf_spec) |> add_recipe(recipe_base)
rf_res <- tune_grid(rf_wf, resamples = cv_folds, grid = rf_grid, metrics = metric_set(rmse, rsq, mae))
?rand_forest
View(df)
# Split
set.seed(123)
split <- initial_split(df, prop = 0.8, strata = specie)  # Para estratificar por classe
split <- initial_split(df, prop = 0.8)  # Para estratificar por classe
train_data <- training(split)
test_data  <- testing(split)
cv_folds <- vfold_cv(train_data, v = 10)
# Receita
recipe_base <-
recipe(specie ~ ., data = train_data) |>
step_normalize(all_predictors())
# ---------------------
# 🌲 Random Forest
# ---------------------
rf_spec <-
rand_forest(mtry = tune(), trees = 300, mode = "classification") |>
set_engine("ranger")
# Divide os dados em 80% treino e 20% teste
# 'strata = specie' garante que a proporção das classes fique balanceada em treino e teste
split <- initial_split(df, prop = 0.8, strata = specie)
# Separa os conjuntos de treino e teste
train_data <- training(split)
test_data  <- testing(split)
# Cria as 10 folds de validação cruzada estratificada
# Isso ajuda a manter a proporção das classes em cada fold
cv_folds <- vfold_cv(train_data, v = 10, strata = specie)
# Divide os dados em 80% treino e 20% teste
# 'strata = specie' garante que a proporção das classes fique balanceada em treino e teste
split <- initial_split(df, prop = 0.8)
# Separa os conjuntos de treino e teste
train_data <- training(split)
test_data  <- testing(split)
# Cria as 10 folds de validação cruzada estratificada
# Isso ajuda a manter a proporção das classes em cada fold
cv_folds <- vfold_cv(train_data, v = 10)
# ---------------------
# 📌 Receita de pré-processamento (Recipe)
# ---------------------
# Define que a variável resposta é 'specie'
# Normaliza todas as variáveis preditoras numéricas (passo opcional dependendo do modelo)
recipe_base <- recipe(specie ~ ., data = train_data) |>
step_normalize(all_predictors())
# ---------------------
# 📌 Receita de pré-processamento (Recipe)
# ---------------------
# Define que a variável resposta é 'specie'
# Normaliza todas as variáveis preditoras numéricas (passo opcional dependendo do modelo)
recipe_base <-
recipe(specie ~ ., data = train_data) |>
step_normalize(all_predictors())
# ---------------------
# 🌲 Especificação do modelo Random Forest para Classificação
# ---------------------
# Define o modelo de Random Forest
# Aqui usamos o motor 'ranger' e deixamos o número de variáveis (mtry) para tunagem
rf_spec <- rand_forest(
mtry = tune(),    # Parâmetro que será otimizado
trees = 300,      # Número de árvores
mode = "classification"  # Agora estamos em modo de classificação
) |> set_engine("ranger")  # Usando o pacote ranger como motor
# ---------------------
# 🌲 Especificação do modelo Random Forest para Classificação
# ---------------------
# Define o modelo de Random Forest
# Aqui usamos o motor 'ranger' e deixamos o número de variáveis (mtry) para tunagem
rf_spec <- rand_forest(
mtry = tune(),    # Parâmetro que será otimizado
trees = 300,      # Número de árvores
mode = "classification"  # Classificação
) |>
set_engine("ranger")  # Usando o pacote ranger como motor
# ---------------------
# 📌 Grade de hiperparâmetros
# ---------------------
# Cria uma grade regular de valores para mtry, de 3 a 9, com 4 níveis
rf_grid <- grid_regular(mtry(range = c(3, 9)), levels = 4)
rf_grid
# ---------------------
# 📌 Grade de hiperparâmetros
# ---------------------
# Cria uma grade regular de valores para mtry, de 3 a 9, com 4 níveis
rf_grid <- grid_regular(mtry(range = c(3, 9)), levels = 6)
rf_grid
# ---------------------
# 📌 Grade de hiperparâmetros
# ---------------------
# Cria uma grade regular de valores para mtry, de 3 a 9, com 4 níveis
rf_grid <- grid_regular(mtry(range = c(3, 9)))
rf_grid
# ---------------------
# 📌 Grade de hiperparâmetros
# ---------------------
# Cria uma grade regular de valores para mtry, de 3 a 9, com 4 níveis
rf_grid <- grid_regular(mtry(range = c(3, 9)), levels = 7)
rf_grid
# ---------------------
# 📌 Workflow
# ---------------------
# Combina a receita e o modelo em um fluxo de trabalho (workflow)
rf_wf <-
workflow() |>
add_model(rf_spec) |>
add_recipe(recipe_base)
# ---------------------
# 📌 Tunagem por validação cruzada
# ---------------------
# Realiza a busca pela melhor combinação de hiperparâmetros da grade
# Avalia usando as métricas de classificação: Accuracy, ROC AUC e Kappa
rf_res <- tune_grid(
rf_wf,                   # Workflow contendo receita e modelo
resamples = cv_folds,    # As folds de validação cruzada
grid = rf_grid,          # A grade de hiperparâmetros
metrics = metric_set(    # Conjunto de métricas de avaliação
accuracy,              # Acurácia
roc_auc,               # Área sob a curva ROC
kap                    # Kappa de Cohen
)
)
# ---------------------
# 📌 Seleção dos melhores hiperparâmetros
# ---------------------
best_rf <- select_best(rf_res, metric = "accuracy")  # Seleciona a melhor combinação com base na acurácia
best_rf
# ---------------------
# 📌 Finalização do Workflow com os melhores parâmetros
# ---------------------
final_rf_wf <- finalize_workflow(rf_wf, best_rf)
# ---------------------
# 📌 Ajuste final no conjunto de treino + avaliação no conjunto de teste
# ---------------------
final_rf_fit <- last_fit(final_rf_wf, split = split, metrics = metric_set(accuracy, roc_auc, kap))
# ---------------------
# 📌 Resultados finais
# ---------------------
# Métricas no conjunto de teste
collect_metrics(final_rf_fit)
# Previsões no conjunto de teste (se quiser visualizar ou salvar)
final_predictions <- collect_predictions(final_rf_fit)
final_predictions
View(final_predictions)
# Matriz de confusão
conf_mat(final_predictions, truth = specie, estimate = .pred_class)
?conf_mat
final_predictions$.pred_class
# Matriz de confusão
cm <- conf_mat(final_predictions, truth = specie, estimate = .pred_class)
plot(cm)
autoplot(cm)
?autoplot
class(cm)
?autoplot.conf_mat
best_rf
plot(best_rf)
View(final_rf_wf)
final_rf_wf[["post"]]
final_rf_fit
View(final_rf_fit)
final_rf_fit
?final_rf_fit
svm_spec <- svm_rbf(
mode = "classification",     # Modo classificação
cost = tune(),               # Parâmetro de penalização (C)
rbf_sigma = tune()           # Parâmetro sigma do kernel RBF
) |> set_engine("kernlab")
svm_grid <- grid_regular(
cost(range = c(0.25, 2)),          # Faixa de custo
rbf_sigma(range = c(0.01, 0.1)),   # Faixa de sigma
levels = 3                         # 3 níveis para cada
)
svm_wf <-
workflow() |>
add_model(svm_spec) |>
add_recipe(recipe_base)
svm_res <- tune_grid(
svm_wf,
resamples = cv_folds,
grid = svm_grid,
metrics = metric_set(accuracy, roc_auc, kap)
)
svm_grid
svm_res <- tune_grid(
svm_wf,
resamples = cv_folds,
# grid = svm_grid,
metrics = metric_set(accuracy, roc_auc, kap)
)
knn_spec <- nearest_neighbor(
neighbors = tune()           # Número de vizinhos
) |> set_engine("kknn") |>
set_mode("classification")   # Modo classificação
knn_grid <- grid_regular(
neighbors(range = c(3, 15)),
levels = 5
)
knn_wf <- workflow() |>
add_model(knn_spec) |>
add_recipe(recipe_base)
knn_res <- tune_grid(
knn_wf,
resamples = cv_folds,
grid = knn_grid,
metrics = metric_set(accuracy, roc_auc, kap)
)
knn_res <- tune_grid(
knn_wf,
resamples = cv_folds,
# grid = knn_grid,
metrics = metric_set(accuracy, roc_auc, kap)
)
rf_res
# ---------------------
# 📌 Seleção dos melhores hiperparâmetros
# ---------------------
best_rf <- select_best(rf_res, metric = "accuracy")  # Seleciona a melhor combinação com base na acurácia
summary(rf_res)
# ---------------------
# 📌 Seleção dos melhores hiperparâmetros
# ---------------------
best_rf <- select_best(rf_res, metric = "accuracy")  # Seleciona a melhor combinação com base na acurácia
# ---------------------
# 📌 Finalização do Workflow com os melhores parâmetros
# ---------------------
final_rf_wf <- finalize_workflow(rf_wf, best_rf)
# ---------------------
# 📌 Ajuste final no conjunto de treino + avaliação no conjunto de teste
# ---------------------
final_rf_fit <- last_fit(final_rf_wf, split = split, metrics = metric_set(accuracy, roc_auc, kap))
# ---------------------
# 📌 Resultados finais
# ---------------------
# Métricas no conjunto de teste
collect_metrics(final_rf_fit)
# Previsões no conjunto de teste (se quiser visualizar ou salvar)
final_predictions <- collect_predictions(final_rf_fit)
# Matriz de confusão
conf_mat(final_predictions, truth = specie, estimate = .pred_class)
df |>
slice_sample(n = 1)
df2 <-
df |>
slice_sample(n = 1) |>
select(-c(specie))
predict(rf_res, new_data = df2)
predict(final_rf_fit, new_data = df2)
final_model <- extract_workflow(final_rf_fit)
predict(final_model, new_data = df2)
df |>
slice_sample(n = 1)
df2 <-
df |>
slice_sample(n = 1) |>
select(-c(specie))
final_model <- extract_workflow(final_rf_fit)
predict(final_model, new_data = df2)
df2 <-
df |>
slice_sample(n = 1) |>
select(-c(specie))
final_model <- extract_workflow(final_rf_fit)
df2
df2 <-
df |>
slice_sample(n = 1)
final_model <- extract_workflow(final_rf_fit)
predict(final_model, new_data = df2)
df2
predict(final_model, new_data = df2 |> select(-specie))
df2
df2 <-
df |>
slice_sample(n = 1)
final_model <- extract_workflow(final_rf_fit)
df2
predict(final_model, new_data = df2 |> select(-specie))
xgb_spec <- boost_tree(
trees = tune(),              # Número de árvores
tree_depth = tune(),          # Profundidade da árvore
learn_rate = tune(),          # Taxa de aprendizado
mode = "classification"       # Modo classificação
) |> set_engine("xgboost")
xgb_grid <- grid_regular(
trees(range = c(100, 200)),
tree_depth(range = c(3, 9)),
learn_rate(range = c(0.05, 0.3)),
levels = 3
)
xgb_wf <- workflow() |>
add_model(xgb_spec) |>
add_recipe(recipe_base)
xgb_res <- tune_grid(
xgb_wf,
resamples = cv_folds,
grid = xgb_grid,
metrics = metric_set(accuracy, roc_auc, kap)
)
library(metan)
MTSI_index2 <-
data_ge2 %>%
waasb(ENV, GEN, REP,
resp = c(KW, NKE, PH, EH, TKW),
mresp = c("h, h, l, l, h"),
wresp = 65) %>% # Default is 50
mtsi(SI = 20)
plot(MTSI_index2)
View(MTSI_index2)
View(MTSI_index2[["MTSI"]])
